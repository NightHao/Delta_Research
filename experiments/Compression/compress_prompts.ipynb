{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= Entity Chunks for VEHICLE-TO-GRID =================================\n",
      "Entity: VEHICLE-TO-GRID\n",
      "Description: The requirement V2G3-M06-14 is related to the V2G process as it specifies conditions for initiating the V2G charging loop The EV is involved in the V2G process, which includes charging and communication with the grid HLC-C is involved in the V2G setup, facilitating communication between the vehicle and the grid V2G is a set of standards that falls under the ISO 15118 specifications EVCC is a component involved in V2G technology, facilitating communication between the electric vehicle and the grid SECC is a component involved in V2G technology, facilitating communication between the charging station and the electric vehicle PICS_CMN_CMN_CombinedTesting involves V2G messaging as part of the testing The test case TC_SECC_AC_VTB_PLCLinkStatus_003 is designed to test scenarios within the V2G communication framework SessionStopReq is a protocol message used within the V2G communication technology\n",
      "The SessionStopReq message is a protocol used within V2G communication to manage session states\n",
      "The SessionStopReq message is part of the V2G communication protocol used to manage sessions\n",
      "The SessionStopReq message is part of the V2G communication protocol to manage session states\n",
      "SessionStopReq is a protocol message used within the V2G technology to manage communication sessions\n",
      "The SessionStopReq message is used to manage V2G communication sessions The ISO:15118‐3:2015:IS standard provides the specifications for V2G communication\n",
      "ISO:15118‐3:2015:IS is a standard that specifies the communication interface for V2G technology\n",
      "The ISO:15118‐3:2015:IS standard specifies the communication interface for V2G technology\n",
      "The standard ISO:15118‐3:2015:IS provides guidelines for V2G communication\n",
      "The ISO:15118‐3:2015:IS standard provides specifications for V2G communication The B1/B2 transition is a process within V2G communication to manage session states The SDP procedure is part of the V2G communication process to ensure readiness for service binding The test case involves initiating and pausing a V2G communication session The test case involves initiating and managing a V2G communication session The test case involves pausing and resuming a V2G communication session The test case TC_SECC_DC_VTB_PLCLinkStatus_001 is designed to test aspects of V2G communication The test case process involves initiating and managing a V2G communication session The test case involves initiating and resuming a V2G communication session The test case is designed to verify the termination of a V2G communication session The test case TC_SECC_DC_VTB_PLCLinkStatus_006 is designed to evaluate aspects of V2G communication ISO:15118‐3:2015 provides the standards for V2G communication BCB toggling is a part of managing V2G communication sessions The test case involves a paused V2G communication session The test case involves a V2G communication session The test case is related to the V2G technology as it involves testing communication sessions between electric vehicles and the grid The test case is designed to evaluate the V2G communication session The test case involves procedures related to V2G communication <|COMPLETE|>\n",
      "V2G represents a set of standards related to vehicle-to-grid communication and technology\n",
      "Vehicle-to-Grid is a system that allows electric vehicles to communicate with the power grid to exchange energy and information, enabling them to return electricity or draw it.\n",
      "Vehicle-to-Grid (V2G) technology enables bidirectional communication and energy exchange between electric vehicles and the power grid, allowing vehicles to return electricity, manage charging rates, and balance demand. V2G Vehicle‐to‐Grid\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: B1/B2 TRANSITION\n",
      "Description: A process in V2G communication where the system transitions between different states or phases, such as waking up from a paused session The test configuration is illustrated in Figure 3. The type of the V2G components and ports (EVCC or SECC) depends on the SUT type.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: BCB\n",
      "Description: A term referring to a component or process involved in toggling during the test case to resume a paused session\n",
      "A term referring to a component or process involved in toggling during the validation sequence\n",
      "A term referring to a component or system involved in the toggling process during EVSE validation\n",
      "Booster Circuit Breaker (BCB) is a component used to manage electrical connections in V2G systems\n",
      "BCB refers to a toggle configuration or state used in the validation process of communication protocols\n",
      "BCB refers to a component or process involved in toggling or transitioning states during a V2G communication session\n",
      "BCB stands for Basic Control Block, a term used in the context of electric vehicle communication and control processes\n",
      "A term referring to the Breaker Control Block, which is toggled during the validation process to test system responses.\n",
      "A term referring to a component or process involved in toggling or switching during the wake-up process and communication sessions in V2G communication.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: ELECTRIC VEHICLE\n",
      "Description: <|COMPLETE|>\n",
      "An Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion and can be charged through the grid\n",
      "An Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion and can detect communication loss during charging\n",
      "An Electric Vehicle (EV) is a type of vehicle that uses electric power for propulsion and must comply with local frequency legislation through the EVSE\n",
      "An Electric Vehicle (EV) that initiates the signal strength measurement process\n",
      "An Electric Vehicle (EV) that participates in the validation process by sending and receiving protocol messages\n",
      "An Electric Vehicle, which is a type of vehicle powered by electric motors using energy stored in rechargeable batteries\n",
      "An electric vehicle that processes incoming messages and interacts with EVSEs during the parameter exchange and matching process\n",
      "An electric vehicle that requires connection to a communication module for charging and data exchange\n",
      "EV refers to Electric Vehicle, which is a type of vehicle that operates on electric power and participates in vehicle-to-grid communication\n",
      "EV refers to an Electric Vehicle, which is a type of vehicle that operates on electric power\n",
      "Electric Vehicle (EV) is a type of vehicle that operates using electric power instead of traditional fuel\n",
      "Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion and can be charged via a power outlet\n",
      "Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion and can communicate with EVSE by sending public keys\n",
      "Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion and is involved in the triggering process immediately after the plug-in of the cable assembly\n",
      "Electric Vehicle (EV) is a type of vehicle that uses electric power for propulsion, mentioned in the context of power flow with EVSE\n",
      "Electric Vehicle (EV) that connects to and disconnects from the logical network\n",
      "Electric Vehicle, a general term for vehicles that operate on electric power, including BEVs and PHEVs\n",
      "Electric Vehicle, a type of vehicle that is powered by electricity instead of traditional fuel sources\n",
      "Electric Vehicle, a type of vehicle that uses electric motors for propulsion and is capable of being charged through an external power source\n",
      "Electric Vehicle, which can decide whether to follow the EVSE's recommendation or proceed with the validation process\n",
      "Electric Vehicle, which initiates the validation process by sending a readiness signal\n",
      "Electric Vehicle, which interacts with EVSE for charging and communication processes\n",
      "Electric Vehicle, which is a type of vehicle powered by electricity and capable of interacting with EVSE for charging\n",
      "Electric Vehicle, which is capable of making decisions on how to proceed in certain situations\n",
      "Electric Vehicle, which is expected to be prepared for a forced restart by an EVSE during the T_conn_resetup waiting state\n",
      "Electric Vehicle, which is involved in the communication process and message exchanges in the test case\n",
      "Electric Vehicle, which is involved in the validation process and must perform certain actions based on the protocol message\n",
      "Electric Vehicle, which is involved in the vehicle-to-grid communication process and must adhere to specific requirements\n",
      "Electric Vehicle, which is involved in the vehicle-to-grid communication process and must continue the matching process if certain conditions are met\n",
      "Electric Vehicle, which is the recipient of charging and communication from the EVSE\n",
      "Electric Vehicle, which is the recipient of communication from the EVSE and must comply with certain PSD values\n",
      "Electric Vehicle, which is the recipient of the CM_SLAC_PARM.CNF message in the context of vehicle-to-grid communication\n",
      "Electric Vehicle, which is the recipient of the communication from the low-layer communication module\n",
      "Electric Vehicle, which is the subject of the protocol command to change its state\n",
      "Electric Vehicle, which is the subject of the requirement to continue with the communication process\n",
      "Electric Vehicle, which is the subject of the timers and validation process described\n",
      "Electric Vehicle, which is the type of vehicle involved in the matching process mentioned\n",
      "Electric Vehicle, which is the type of vehicle involved in the parallel injection process\n",
      "Electric Vehicle, which participates in the SLAC process and communicates with EVSE\n",
      "Electric Vehicle, which uses electricity as its primary source of propulsion\n",
      "Electric Vehicle, which uses the low-layer communication module for various communication processes\n",
      "Electric Vehicle, which uses the method to discover and select communication nodes based on signal strength\n",
      "An Electric Vehicle (EV) is powered by electric motors and batteries for propulsion, offering an alternative to internal combustion engine vehicles.\n",
      "An Electric Vehicle (EV) uses electric power for propulsion and is involved in vehicle-to-grid communication processes.\n",
      "EV stands for Electric Vehicle, which is powered by electricity and uses electric motors for propulsion instead of traditional fuel sources.\n",
      "Electric Vehicles (EVs), which are powered by electric motors, use energy stored in rechargeable batteries.\n",
      "An Electric Vehicle is a type of vehicle that operates using electric power stored in batteries and is powered by electric motors.\n",
      "Electric Vehicle, a type of vehicle powered by electricity.\n",
      "Electric Vehicle is involved in the validation process with Electric Vehicle Supply Equipment (EVSE).\n",
      "Electric Vehicles (EVs) are powered by electric motors and batteries instead of internal combustion engines.\n",
      "Electric Vehicles are a type of vehicle that use electric motors for propulsion and require charging infrastructure.\n",
      "An Electric Vehicle (EV) is a type of vehicle that uses electric motors for propulsion, requires charging infrastructure like EVSE, and can communicate with it for charging and validation processes.\n",
      "Electric Vehicle (EV) is a type of vehicle that operates on electric power using electric motors for propulsion, powered by electricity stored in rechargeable batteries or fuel cells.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: EVCC\n",
      "Description: EVCC refers to a set of non-standardized processing timeouts related to Electric Vehicle Communication Controller\n",
      "Electric Vehicle Communication Controller, a component involved in electric vehicle charging systems, subject to testing under IEC 61851-1\n",
      "<|COMPLETE|>\n",
      "Electric Vehicle Communication Controller, which acts as a client in the communication protocol\n",
      "Electric Vehicle Communication Controller, a component involved in the control and execution of test cases and behaviors in the test suite\n",
      "Electric Vehicle Communication Controller, a technology component involved in the communication process during validation\n",
      "A segment in the example identifier, possibly referring to Electric Vehicle Communication Controller\n",
      "The Electric Vehicle Communication Controller, a system within the EV, is responsible for managing communication and validation processes with the Electric Vehicle Supply Equipment (EVSE).\n",
      "The Electric Vehicle Communication Controller, a system under test in the ISO 15118 standard, is responsible for managing communication between the electric vehicle and the charging station.\n",
      "The Electric Vehicle Communication Controller manages communication between electric vehicles and charging stations and infrastructure, facilitating charging communication.\n",
      "The Electric Vehicle Communication Controller (EVCC) manages communication between electric vehicles and charging stations, including infrastructure for DC charging. Requirements of transmission power limitation for EVCC or SECC testing are specified.\n",
      "If the SUT is an EVCC, the MTC shall use the type EVCC_Tester.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: HIGH-LEVEL COMMUNICATION\n",
      "Description: <|COMPLETE|>\n",
      "A communication technology that manages and controls the charging process of electric vehicles through advanced communication protocols\n",
      "A protocol mode used for high-level communication during the charging process of electric vehicles\n",
      "A protocol or communication layer involved in the high-level control of a process, possibly related to vehicle-to-grid communication\n",
      "A term possibly referring to a high-level communication component or process in the V2G setup\n",
      "HLC-C is a protocol or communication standard that some electric vehicles support for advanced communication capabilities\n",
      "HLC-C is a protocol used in the context of vehicle-to-grid (V2G) communication, possibly for high-level communication control\n",
      "HLC-C refers to a protocol used in communication messages to determine the maximum charge current for electric vehicle charging)\n",
      "High-Level Communication, a protocol or system used for advanced communication between an electric vehicle and a charging station\n",
      "High-level communication involves the exchange of complex data and commands between systems, often requiring sophisticated protocols and interfaces\n",
      "High-Level Communication Charging is a method and protocol for controlling charging processes through advanced communication techniques.\n",
      "High-Level Communication (HLC-C), a protocol for electric vehicles, facilitates advanced features and bidirectional communication with the charging infrastructure.\n",
      "HLC-C is a high-level communication protocol that facilitates communication between electric vehicle supply equipment (EVSE) and vehicles, managing interactions with charging stations and controlling the charging process. During the V2G charging loop, the PWM duty cycle shall not change due to dynamically changed grid information. Those dynamically changed grid limitations shall be provided through the high-level communication messages.\n",
      "The EV’s communication node shall implement one of the two following options with receiving a D-LINK_ERROR.request from HLE.\n",
      "The EV shall always charge in the HLC-C mode, as soon as V2G charging loop is started.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: ISO 15118\n",
      "Description: An international standard defining communication protocols for electric vehicle charging\n",
      "An international standard for the communication interface between electric vehicles and the electric vehicle supply equipment\n",
      "ISO 15118 is a standard for vehicle-to-grid communication interface, which includes test suite conventions for verdict handling\n",
      "ISO 15118 is a standard for vehicle-to-grid communication interface, which includes definitions and explanations of unique terminologies\n",
      "A standard that defines the communication interface between electric vehicles and the electric vehicle supply equipment, focusing on the physical and data link layers\n",
      "ISO 15118 is a standard for the communication interface between electric vehicles and the electric vehicle supply equipment, focusing on conformance testing and interoperability\n",
      "ISO 15118 is a standard that covers communication protocols for electric vehicle charging, including both AC and DC use-cases\n",
      "ISO 15118 is a standard that covers the communication interface between electric vehicles and charging stations, including high-level communication modules for EVSEs\n",
      "ISO 15118 is a set of standards that describe the use cases and technical specifications for the Vehicle-to-Grid Communication Interface, aimed at optimizing energy resource use for electric road vehicles\n",
      "ISO 15118 is a standard for vehicle-to-grid communication interface, which includes test suite naming conventions for PICS/PIXIT identifiers\n",
      "A standard for vehicle-to-grid communication interface, which the conformance tests in Annex D and E are based on\n",
      "ISO 15118 is a standard that covers the overall information exchange between all actors involved in the electrical energy exchange, specifically applicable for manually connected conductive charging\n",
      "ISO 15118 is a part of the International Standards Organization's specifications, under which V2G standards fall\n",
      "An international standard for vehicle-to-grid communication interface defines the communication between electric vehicles and the grid.\n",
      "ISO 15118 is a standard for vehicle-to-grid communication interface that includes specifications for test suite modules and naming conventions for template identifiers, test case identifiers, modules, and function names.\n",
      "ISO 15118 is a series of international standards for vehicle-to-grid communication that specifies the requirements and protocols for the interface between electric vehicles, charging stations, and the grid, focusing on both charging and discharging. Road vehicles — Vehicle to grid communication interface — Part 3: Physical and data link layer requirements\n",
      "INTERNATIONAL STANDARD ISO 15118-5 First edition 2018-02 and ISO 15118-3 First edition 2015-05-15 detail the vehicle to grid communication interface.\n",
      "V2G represents the ISO 15118 set of standards.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: ISO:15118‐3:2015\n",
      "Description: A part of the ISO 15118 series, this standard specifies the communication interface between electric vehicles and the grid, focusing on physical and data link layers\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: ISO:15118‐3:2015:IS\n",
      "Description: An international standard document that provides guidelines and specifications for the test case TC_SECC_CMN_VTB_CmValidate_003\n",
      "A standard document that provides sections referenced in the test case description\n",
      "An international standard that specifies the communication interface between electric vehicles and the power grid for V2G applications\n",
      "An international standard document that provides guidelines and specifications for SECC communication and SLAC parameter handling\n",
      "An international standard document that provides guidelines and requirements for the test case TC_SECC_CMN_VTB_CmAmpMap_003\n",
      "An international standard document that provides specifications for V2G communication, including sections relevant to the test case\n",
      "An international standard document that specifies the communication interface between electric vehicles and electric vehicle supply equipment.\n",
      "An international standard document provides guidelines and sections relevant to the test case, including 15118‐3:A.9.2.1, 15118‐3:6.4.3.2, 15118‐3:A.9.6.1, 15118‐3:A.9.6.2, 15118‐3:A.9.6.3.2, and 15118‐3:9.4.\n",
      "An international standard document that provides specifications and requirements for V2G communication interfaces.\n",
      "An international standard document that provides guidelines and specifications for electric vehicle communication interfaces, referenced in the test case.\n",
      "An international standard document that provides guidelines and specifications for communication protocols and interfaces in electric vehicle charging.\n",
      "An international standard document that provides guidelines and specifications for vehicle-to-grid communication interfaces relevant to the test case.\n",
      "An international standard provides specifications and guidelines for electric vehicle communication interfaces, focusing on the physical and data link layers for communication with the grid and electric vehicle supply equipment.\n",
      "An international standard specifies the communication interface between electric vehicles and the grid, encompassing protocols, requirements, test case descriptions, and guidelines that focus on the physical and data link layers, message exchanges, and validation processes.\n",
      "An international standard document that provides guidelines and specifications for test cases, including specific requirements, test procedures, validation processes, and referenced sections.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: PICS_CMN_CMN_COMBINEDTESTING\n",
      "Description: PICS_CMN_CMN_CombinedTesting is a requirement for conducting combined testing of various communication protocols and processes\n",
      "PICS_CMN_CMN_CombinedTesting is a requirement that influences the execution of combined testing scenarios in PLCLinkStatus\n",
      "A term indicating that combined testing is enabled in the PICS configuration\n",
      "A requirement for combined testing in the SECC communication process\n",
      "Indication for enabling combined testing including SLAC association and V2G messaging\n",
      "A term referring to a combined testing mode in the PICS common configuration\n",
      "A term referring to a combined testing scenario in electric vehicle communication systems\n",
      "A term indicating a combined testing condition in a protocol implementation conformance statement\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: SDP PROCEDURE\n",
      "Description: The Service Discovery Protocol (SDP) procedure used in V2G communication to ensure the system is ready for the binding process\n",
      "Service Discovery Protocol (SDP) procedure used in the V2G communication session to ensure the system is ready for the Binding process\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: SECC\n",
      "Description: Supply Equipment Communication Controller, which acts as a server in the communication protocol\n",
      "Supply Equipment Communication Controller, a component involved in electric vehicle charging systems, subject to testing under IEC 61851-1\n",
      "Supply Equipment Communication Controller, a component involved in the control and execution of test cases and behaviors in the test suite\n",
      "<|COMPLETE|>\n",
      "SECC refers to the Smart Electric Car Consortium, which is involved in developing standards and protocols for electric vehicle communication and charging\n",
      "SECC refers to the organization or system involved in the testing and validation of communication protocols\n",
      "Supply Equipment Communication Controller, a system under test in the ISO 15118 standard\n",
      "Supply Equipment Communication Controller, a system under test in the ISO 15118 standard, responsible for managing communication between the charging station and the electric vehicle\n",
      "SECC refers to a set of non-standardized processing timeouts related to Supply Equipment Communication Controller\n",
      "An organization or entity responsible for managing SLAC operations, possibly in an EVSE context\n",
      "SECC refers to the organization or system involved in electric vehicle communication, testing, and the configuration of communication standards.\n",
      "The Supply Equipment Communication Controller is a component in electric vehicle charging systems that manages communication and processes between electric vehicles and charging stations.\n",
      "The Supply Equipment Communication Controller (SECC), a component in electric vehicle charging systems, manages communication and state changes between electric vehicles and charging stations during charging. Requirements of transmission power limitation for EVCC or SECC testing are specified.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: SESSIONSTOPREQ\n",
      "Description: A protocol message used to request the termination of a V2G communication session\n",
      "A protocol message used to request the stopping of a session, including parameters like SessionID and ChargingSession status\n",
      "A protocol message used to stop a session in V2G communication.\n",
      "A protocol message that requests to stop or pause a V2G communication session, including parameters such as SessionID and ChargingSession status.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_EVCC_AC_VTB_PLCLINKSTATUS_001\n",
      "Description: A specific test case identifier used in the context of testing, likely related to the communication or link status in electric vehicle charging systems\n",
      "<|COMPLETE|>\n",
      "A test case identifier for a specific procedure involving the execution of a GoodCase procedure and management of a paused V2G communication session\n",
      "A specific test case identifier used in the context of electric vehicle communication, likely related to testing the status of a PLC (Power Line Communication) link in an AC (Alternating Current) vehicle-to-building scenario)\n",
      "A test case process executed to verify the PLCLinkStatus under specific conditions involving AC vehicle-to-grid communication Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_EVCC_AC_VTB_PLCLINKSTATUS_002\n",
      "Description: A test case process executed to verify the PLCLinkStatus under different conditions involving AC vehicle-to-grid communication\n",
      "<|COMPLETE|>\n",
      "A specific test case description related to the Electric Vehicle Communication Controller (EVCC) and Power Line Communication (PLC) link status in an AC vehicle-to-building (VTB) context)\n",
      "A test case procedure executed by the Test System to verify the handling of a paused V2G communication session initiated by the System Under Test (SUT)\n",
      "A specific test case identifier used in testing, likely related to Electric Vehicle Communication Controller (EVCC) and Power Line Communication (PLC) link status. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_EVCC_AC_VTB_PLCLINKSTATUS_006\n",
      "Description: A test case identifier for a specific procedure related to V2G communication and PLC link status\n",
      "A specific test case identifier used in the context of testing, likely related to the communication or link status in electric vehicle charging systems\n",
      "<|COMPLETE|>\n",
      "A test case process executed to verify the PLCLinkStatus under specific conditions without pause\n",
      "A specific test case description related to the communication status of the Power Line Communication (PLC) link in an Electric Vehicle Communication Controller (EVCC) during AC charging) Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_EVCC_DC_VTB_PLCLINKSTATUS_003\n",
      "Description: A test case identifier used to describe a specific test scenario related to the V2G communication session and PLC link status\n",
      "A specific test case identifier used in the context of testing electric vehicle communication controller (EVCC) direct current (DC) vehicle-to-building (VTB) power line communication (PLC) link status)\n",
      "<|COMPLETE|>\n",
      "A specific test case identifier used in testing procedures, likely related to electric vehicle communication and power line communication link status\n",
      "A test case process executed to verify the PLC link status when no pause condition is present Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_EVCC_DC_VTB_PLCLINKSTATUS_005\n",
      "Description: A test case process executed to verify the PLC link status under sleep after charge conditions\n",
      "<|COMPLETE|>\n",
      "A test case identifier for a specific procedure involving V2G communication and session management\n",
      "A specific test case identifier used in electric vehicle communication and power line communication link status, particularly in direct current vehicle-to-building scenarios and testing procedures. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_AC_VTB_PLCLINKSTATUS_003\n",
      "Description: A specific test case identifier used in a testing framework, likely related to the status of a PLC (Power Line Communication) link in an AC (Alternating Current) vehicle-to-building scenario\n",
      "A further test case process for checking the PLC link status in the SECC system under conditions involving pause and combined testing\n",
      "A test case identifier used to describe a specific scenario in V2G communication testing, focusing on the PLC link status and session management\n",
      "<|COMPLETE|>\n",
      "A specific test case description related to the status of the PLC link in the context of AC vehicle-to-building communication) Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_AC_VTB_PLCLINKSTATUS_004\n",
      "Description: A test case identifier used to describe a specific test scenario related to V2G communication and PLC link status\n",
      "A specific test case identifier used in testing procedures, likely related to the status of a PLC (Power Line Communication) link in an AC (Alternating Current) vehicle-to-building (VTB) context Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_AC_VTB_PLCLINKSTATUS_010\n",
      "Description: <|COMPLETE|>\n",
      "A test case procedure designed to execute a GoodCase scenario, initiate a paused V2G communication session, and verify various system behaviors such as wake-up process and BCB toggle detection\n",
      "A test case process executed under specific conditions related to PLC link status in SECC AC\n",
      "A specific test case identifier used for testing the PLC link status in an AC vehicle-to-building scenario, as detailed in a table of test case descriptions. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_AC_VTB_PLCLINKSTATUS_012\n",
      "Description: A test case procedure that involves executing a GoodCase procedure, pausing a V2G communication session, and resuming it with specific parameters and conditions\n",
      "<|COMPLETE|>\n",
      "A test case process executed under specific conditions related to PLC link status in SECC AC\n",
      "A specific test case identifier related to the PLC (Power Line Communication) link status in an AC (Alternating Current) vehicle-to-building (VTB) context, likely used within a testing framework. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_DC_VTB_PLCLINKSTATUS_001\n",
      "Description: <|COMPLETE|>\n",
      "A test case identifier used to describe a specific scenario in the testing of V2G communication, focusing on the PLC link status and session management\n",
      "A specific test case identifier related to the PLC link status in a DC vehicle-to-building and vehicle-to-grid scenario. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_DC_VTB_PLCLINKSTATUS_002\n",
      "Description: A specific test case identifier used in the context of testing, likely related to the communication or link status in a system involving power line communication (PLC) and electric vehicle charging)\n",
      "<|COMPLETE|>\n",
      "A specific test case identifier used in a table listing test case descriptions, likely related to testing the PLC link status in a DC vehicle-to-building context)\n",
      "A test case process where the Test System executes a GoodCase procedure to initiate a paused V2G communication session and checks various parameters and processes\n",
      "A specific test case description related to the PLC (Power Line Communication) link status in a DC (Direct Current) vehicle-to-building (VTB) context) Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_DC_VTB_PLCLINKSTATUS_003\n",
      "Description: <|COMPLETE|>\n",
      "A test case designed to execute a GoodCase procedure, initiate a paused V2G communication session, and resume it by initiating a BCB toggle while checking for failed link detection and ensuring the SUT does not turn off the +12 V supply during the sleeping phase\n",
      "A test case designed to verify the PLC link status in a direct current electric vehicle charging context\n",
      "A specific test case identifier used in a testing framework related to the communication link status in a direct current vehicle-to-building scenario using power line communication (PLC). Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_DC_VTB_PLCLINKSTATUS_005\n",
      "Description: A test case identifier used to describe a specific test scenario for verifying the termination of a V2G communication session\n",
      "<|COMPLETE|>\n",
      "A specific test case identifier related to the PLC link status in electric vehicle charging and DC vehicle-to-building or vehicle-to-grid scenarios. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: TC_SECC_DC_VTB_PLCLINKSTATUS_006\n",
      "Description: <|COMPLETE|>\n",
      "A test case identifier used to describe a specific scenario in the testing of V2G communication, focusing on the PLC link status and session management\n",
      "A specific test case identifier related to the PLC (Power Line Communication) link status in a DC (Direct Current) vehicle-to-building or vehicle-to-grid scenario. Test steps where the test system sends stimuli to the SUT that are valid (syntactically and semantically) according to the protocol requirements.\n",
      "--------------------------------------------------------------------------------\n",
      "Entity: V2G3-M06-14\n",
      "Description: A specific requirement indicating that the electric vehicle (EV) must always charge in the HLC-C mode when the V2G charging loop is initiated\n",
      "--------------------------------------------------------------------------------\n",
      "You need to answer the following question as more details as possible based on the provided information above\n",
      " Question: What is the system architecture of Vehicle-to-Grid?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "prompt_dict = json.load(open(\"./final_prompt.json\"))\n",
    "prompt_list = list(prompt_dict.values())\n",
    "question = list(prompt_dict.keys())\n",
    "print(prompt_dict[question[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742d2bc16f0e4ebeafaec8976c0323fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6870 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 existing compressed prompts\n",
      "Saved compressed prompt for question: What is the system architecture of Vehicle-to-Grid?\n",
      "Saved compressed prompt for question: What is HomePlug Green PHY?\n",
      "Saved compressed prompt for question: What is Signal Level Attenuation Characterization?\n",
      "Saved compressed prompt for question: What is Logical Network?\n",
      "Saved compressed prompt for question: What is Central Coordinator?\n",
      "Saved compressed prompt for question: What is the difference between Service Access Point for Data and Data link control SAP?\n",
      "Saved compressed prompt for question: What is the difference between basic signaling and high-level communication?\n",
      "Saved compressed prompt for question: What is the difference between Main Test Component and Parallel Test Component?\n",
      "Saved compressed prompt for question: What is ABSTRACT TEST SUITE?\n",
      "Saved compressed prompt for question: What is TEST SUITE STRUCTURE?\n",
      "Saved compressed prompt for question: What is External Identification Means?\n",
      "Saved compressed prompt for question: What is CM_SLAC_PARM.REQ?\n",
      "Saved compressed prompt for question: What is CM_SLAC_PARM.CNF?\n",
      "Saved compressed prompt for question: What is CM_START_ATTEN_CHAR.IND?\n",
      "Saved compressed prompt for question: What is CM_MNBC_SOUND.IND?\n",
      "Saved compressed prompt for question: What is CM_ATTEN_CHAR.IND?\n",
      "Saved compressed prompt for question: What is CM_ATTEN_CHAR.RSP?\n",
      "Saved compressed prompt for question: What is CM_ATTEN_PROFILE.IND?\n",
      "Saved compressed prompt for question: What is CM_VALIDATE.REQ?\n",
      "Saved compressed prompt for question: What is CM_VALIDATE.CNF?\n",
      "Saved compressed prompt for question: What is CM_SLAC_MATCH.REQ?\n",
      "Saved compressed prompt for question: What is CM_SLAC_MATCH.CNF?\n",
      "Saved compressed prompt for question: What is CM_SET_KEY.REQ?\n",
      "Saved compressed prompt for question: What is CM_SET_KEY.CNF?\n",
      "Saved compressed prompt for question: What is CM_AMP_MAP.REQ?\n",
      "Saved compressed prompt for question: What is CM_AMP_MAP.CNF?\n",
      "Saved compressed prompt for question: What is D-LINK_READY.indication?\n",
      "Saved compressed prompt for question: What is D-LINK_TERMINATE.request?\n",
      "Saved compressed prompt for question: What is D-LINK_ERROR.request?\n",
      "Saved compressed prompt for question: What is D-LINK_PAUSE.request?\n"
     ]
    }
   ],
   "source": [
    "from llmlingua import PromptCompressor\n",
    "llm_lingua = PromptCompressor(\"microsoft/phi-2\")\n",
    "try:\n",
    "    with open(\"./compressed_prompt.json\", \"r\") as f:\n",
    "        compressed_prompt_dict = json.load(f)\n",
    "    print(f\"Loaded {len(compressed_prompt_dict)} existing compressed prompts\")\n",
    "except FileNotFoundError:\n",
    "    compressed_prompt_dict = {}\n",
    "\n",
    "for question, prompt in prompt_dict.items():\n",
    "    compressed_prompt = llm_lingua.compress_prompt(\n",
    "        prompt,\n",
    "        question=question,\n",
    "        condition_in_question=\"after_condition\",\n",
    "        rate=0.80,\n",
    "        reorder_context=\"sort\",\n",
    "        dynamic_context_compression_ratio=0.3, # or 0.4\n",
    "        condition_compare=True,\n",
    "        context_budget=\"*1.5\",\n",
    "        rank_method=\"longllmlingua\",\n",
    "    )\n",
    "    compressed_prompt_dict[question] = compressed_prompt\n",
    "    \n",
    "    # Save each compressed prompt as we generate it\n",
    "    with open(\"./compressed_prompt.json\", \"w\") as f:\n",
    "        json.dump(compressed_prompt_dict, f, indent=2)\n",
    "        print(f\"Saved compressed prompt for question: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(compressed_prompt_dict, open(\"./compressed_prompt.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be136ae4ab6f42febee8b7a9aacb43ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llmlingua import PromptCompressor\n",
    "llm_lingua = PromptCompressor(\"microsoft/phi-2\")\n",
    "def compress_prompt(question, prompt, compress_ratio):\n",
    "    res = llm_lingua.compress_prompt(\n",
    "                prompt,\n",
    "                # question=question,\n",
    "                # condition_in_question=\"after_condition\",\n",
    "                rate=compress_ratio,\n",
    "                # reorder_context=\"sort\",\n",
    "                # dynamic_context_compression_ratio=0.3, # or 0.4\n",
    "                # condition_compare=True,\n",
    "                # context_budget=\"+100\",\n",
    "                # rank_method=\"longllmlingua\",\n",
    "            )\n",
    "    # compressed_prompt = \"\\n\".join(res['compressed_prompt'].split('\\n')[:-1])\n",
    "    compressed_prompt = res['compressed_prompt']\n",
    "    origin_tokens = res['origin_tokens']\n",
    "    compressed_tokens = res['compressed_tokens']\n",
    "    rate = res['rate']\n",
    "    return [compressed_prompt, origin_tokens, compressed_tokens, rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_entities_dict(data, max_distance=-1):\n",
    "    \"\"\"\n",
    "    Returns a new dictionary containing only the common entities across all chunks,\n",
    "    maintaining the original structure for each entity\n",
    "    Args:\n",
    "        data: dictionary containing entity_chunk_X keys with entity information\n",
    "    Returns:\n",
    "        dict: new dictionary with only common entities\n",
    "    \"\"\"\n",
    "    # First find common entity names across all chunks\n",
    "    chunk_keys = list(data.keys())\n",
    "    if not chunk_keys:\n",
    "        return {}\n",
    "    \n",
    "    # Get common entity names (like 'EIM', 'AC', etc.)\n",
    "    common_entities = set(data[chunk_keys[0]].keys())\n",
    "    for chunk_key in chunk_keys[1:]:\n",
    "        common_entities = common_entities.intersection(set(data[chunk_key].keys()))\n",
    "    \n",
    "    # Create new dictionary with only common entities\n",
    "    common_dict = {}\n",
    "    \n",
    "    # First handle main entities (distance=0)\n",
    "    for chunk_key in chunk_keys:\n",
    "        main_entity = next((entity for entity, info in data[chunk_key].items() \n",
    "                        if info.get('distance') == 0), None)\n",
    "        \n",
    "        if main_entity and (max_distance < 0 or 0 <= max_distance):\n",
    "            if main_entity not in common_dict:\n",
    "                common_dict[main_entity] = data[chunk_key][main_entity]\n",
    "    \n",
    "    # Then handle other common entities\n",
    "    for entity in common_entities:\n",
    "        if entity in common_dict:  # Skip if already added as main entity\n",
    "            continue\n",
    "            \n",
    "        # Find smallest distance for this entity across all chunks\n",
    "        smallest_distance = float('inf')\n",
    "        best_data = None\n",
    "        \n",
    "        for chunk_key in chunk_keys:\n",
    "            entity_data = data[chunk_key].get(entity, {})\n",
    "            distance = entity_data.get('distance', float('inf'))\n",
    "            if distance < smallest_distance:\n",
    "                smallest_distance = distance\n",
    "                best_data = entity_data\n",
    "        \n",
    "        # Only include entity if its smallest distance is within limit\n",
    "        if max_distance < 0 or smallest_distance <= max_distance:\n",
    "            common_dict[entity] = best_data\n",
    "    common_dict = {\"common_entities\": common_dict}\n",
    "    return common_dict\n",
    "\n",
    "def get_unique_entities_dict(data, max_distance=-1):\n",
    "    \"\"\"\n",
    "    Returns a new dictionary containing only the unique entities for each chunk,\n",
    "    maintaining the original structure for each entity\n",
    "    Args:\n",
    "        data: dictionary containing entity_chunk_X keys with entity information\n",
    "    Returns:\n",
    "        dict: new dictionary with only unique entities per chunk\n",
    "    \"\"\"\n",
    "    chunk_keys = list(data.keys())\n",
    "    unique_dict = {}\n",
    "    # For each chunk, find entities that don't appear in any other chunk\n",
    "    for current_chunk in chunk_keys:\n",
    "        current_entities = set(data[current_chunk].keys())\n",
    "        \n",
    "        # Get entities from all other chunks\n",
    "        other_entities = set()\n",
    "        for other_chunk in chunk_keys:\n",
    "            if other_chunk != current_chunk:\n",
    "                other_entities.update(data[other_chunk].keys())\n",
    "        \n",
    "        # Get unique entities for this chunk\n",
    "        unique_entities = current_entities - other_entities\n",
    "        \n",
    "        main_entity = next((entity for entity, info in data[current_chunk].items() \n",
    "                        if info.get('distance') == 0), None)\n",
    "        \n",
    "        # Create new dictionary with unique entities and main entity for this chunk\n",
    "        unique_dict[current_chunk] = {}\n",
    "        \n",
    "        if main_entity:\n",
    "            unique_dict[current_chunk][main_entity] = data[current_chunk][main_entity]\n",
    "            \n",
    "        # Add other unique entities\n",
    "        for entity in unique_entities:\n",
    "            if entity != main_entity:  # Don't add main entity twice\n",
    "                entity_data = data[current_chunk][entity]\n",
    "                distance = entity_data.get('distance', float('inf'))\n",
    "                if max_distance < 0 or distance <= max_distance:\n",
    "                    unique_dict[current_chunk][entity] = entity_data\n",
    "    \n",
    "    return unique_dict\n",
    "\n",
    "def combine_entity_descriptions(data, max_distance=3, entities_chunks_file=None, question=\"\"):\n",
    "    \"\"\"\n",
    "    Combines the 'relationship', 'description', and 'chunk_context' fields\n",
    "    for each entity in the JSON file into a single detailed description.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dictionary containing entity information\n",
    "        max_distance (int): Maximum distance to include entities\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with entity names as keys and their combined descriptions as values.\n",
    "    \"\"\"\n",
    "    entities_chunks = {}\n",
    "    print(entities_chunks_file, question)\n",
    "    # Process entities up to max_distance\n",
    "    for entity_chunk, entities in data.items():\n",
    "        first_one = True\n",
    "        main_entity = \"\"\n",
    "        for entity, details in entities.items():\n",
    "            if details.get('distance') == 0:\n",
    "                if not first_one:\n",
    "                    main_entity += \" & \"\n",
    "                main_entity += entity\n",
    "                first_one = False\n",
    "            else: break\n",
    "        entities_chunks[main_entity] = {}\n",
    "        \n",
    "        # Process entities up to max_distance\n",
    "        for entity, details in entities.items():\n",
    "            dis = details.get('distance')\n",
    "            if dis > max_distance:\n",
    "                continue\n",
    "            \n",
    "            combined_parts = []\n",
    "            \n",
    "            # Extract and append 'relationship' if it's not empty\n",
    "            relationship = details.get('relationship', '').strip()\n",
    "            if relationship:\n",
    "                combined_parts.append(relationship.strip('\"'))  # Remove surrounding quotes if present\n",
    "\n",
    "            # Extract and append 'description' if it's not empty\n",
    "            description = details.get('description', '').strip()\n",
    "            if description:\n",
    "                # Replace <SEP> with a space or another separator if desired\n",
    "                description = description.replace('<SEP>', ' ')\n",
    "                combined_parts.append(description.strip('\"'))  # Remove surrounding quotes if present\n",
    "\n",
    "            # Extract and append 'chunk_context' if it's not empty\n",
    "            chunk_context = details.get('chunk_context', '').strip()\n",
    "            if chunk_context:\n",
    "                combined_parts.append(chunk_context)\n",
    "            result = [\"\", 0, 0, 1.00]\n",
    "            # Join all parts with a space\n",
    "            combined_description = ' '.join(combined_parts)\n",
    "            if dis == 0:\n",
    "                if entities_chunks_file == './fixed_entities_chunks.json':\n",
    "                    result = compress_prompt(question, combined_description, 0.7)\n",
    "                else:\n",
    "                    result = [combined_description, 0, 0, 1.00]\n",
    "            elif dis == 1:\n",
    "                if entities_chunks_file == './fixed_entities_chunks.json':\n",
    "                    result = compress_prompt(question, combined_description, 0.7)\n",
    "                else:\n",
    "                    result = compress_prompt(question, combined_description, 0.8)\n",
    "            elif dis == 2:\n",
    "                if entities_chunks_file == './fixed_entities_chunks.json':\n",
    "                    result = compress_prompt(question, combined_description, 0.7)\n",
    "                else:\n",
    "                    result = compress_prompt(question, combined_description, 0.6)\n",
    "\n",
    "            compressed_description = result[0]\n",
    "            # print(entity, result[3])\n",
    "            compression_stats = {\n",
    "                \"entity\": entity,\n",
    "                \"distance\": dis,\n",
    "                \"original_length\": len(combined_description),\n",
    "                \"compressed_length\": len(compressed_description),\n",
    "                \"compression_ratio\": result[3],\n",
    "                \"tokens_before\": result[1],\n",
    "                \"tokens_after\": result[2],\n",
    "                \"original_prompt\": combined_description,\n",
    "                \"compressed_prompt\": compressed_description\n",
    "            }\n",
    "            \n",
    "            # Load existing stats\n",
    "            try:\n",
    "                with open(\"/home/Lewis/Delta_Research/experiments/Compression/compression_stats.json\", \"r\") as f:\n",
    "                    existing_stats = json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                # File doesn't exist yet or is empty/corrupted\n",
    "                existing_stats = []\n",
    "            \n",
    "            # Append new stats\n",
    "            existing_stats.append(compression_stats)\n",
    "            \n",
    "            # Write all stats back to file as a proper JSON array\n",
    "            with open(\"/home/Lewis/Delta_Research/experiments/Compression/compression_stats.json\", \"w\") as f:\n",
    "                json.dump(existing_stats, f, indent=4)\n",
    "            entities_chunks[main_entity][entity] = compressed_description\n",
    "\n",
    "    return entities_chunks\n",
    "\n",
    "def format_entity_chunks_prompt(data, main_entity):\n",
    "    chunks_prompt = f\"================================= Entity Chunks for {main_entity} =================================\\n\"\n",
    "    for entity, description in data.items():\n",
    "        chunks_prompt += f\"Entity: {entity}\\nDescription: {description}\\n{'-'*80}\\n\"\n",
    "    return chunks_prompt\n",
    "\n",
    "def extend_entities_from_graph(data, max_distance=1):\n",
    "    \"\"\"\n",
    "    Extends the entities in the data by finding their neighbors in the entity graph\n",
    "    up to a specified distance.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dictionary containing entity_chunk_X keys with entity information\n",
    "        max_distance (int): Maximum distance to extend entities in the graph\n",
    "        \n",
    "    Returns:\n",
    "        dict: The original data with additional entities added from the graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the entity graph\n",
    "        entity_graph = json.load(open(\"/home/Lewis/Delta_Research/optimized_entity_graph.json\"))\n",
    "        if not entity_graph:\n",
    "            print(\"Warning: Could not load entity graph, returning original data\")\n",
    "            return data\n",
    "            \n",
    "        # Create a deep copy to avoid modifying the original data\n",
    "        import copy\n",
    "        extended_data = copy.deepcopy(data)\n",
    "        \n",
    "        # For each chunk in the data\n",
    "        for chunk_key, entities in extended_data.items():\n",
    "            # Find all entities at the boundary (maximum distance in current data)\n",
    "            current_max_distance = max([details.get('distance', 0) for entity, details in entities.items()])\n",
    "            boundary_entities = [entity for entity, details in entities.items() \n",
    "                                if details.get('distance') == current_max_distance]\n",
    "            \n",
    "            # Track processed entities to avoid duplicates\n",
    "            processed_entities = set(entities.keys())\n",
    "            \n",
    "            # For each entity at the boundary\n",
    "            for boundary_entity in boundary_entities:\n",
    "                _extend_entity_neighbors(\n",
    "                    entity_graph, \n",
    "                    extended_data[chunk_key], \n",
    "                    boundary_entity, \n",
    "                    current_max_distance,\n",
    "                    processed_entities, \n",
    "                    max_depth=max_distance\n",
    "                )\n",
    "                \n",
    "        return extended_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extending entities from graph: {e}\")\n",
    "        return data\n",
    "        \n",
    "def _extend_entity_neighbors(entity_graph, entities_dict, entity_name, current_distance, \n",
    "                            processed_entities, max_depth=1, current_depth=0):\n",
    "    \"\"\"\n",
    "    Recursively extends entity neighbors from the graph.\n",
    "    \n",
    "    Args:\n",
    "        entity_graph (dict): The loaded entity graph\n",
    "        entities_dict (dict): The dictionary to add new entities to\n",
    "        entity_name (str): The current entity to find neighbors for\n",
    "        current_distance (int): The current distance in the original data\n",
    "        processed_entities (set): Set of already processed entity names\n",
    "        max_depth (int): Maximum recursion depth\n",
    "        current_depth (int): Current recursion depth\n",
    "    \"\"\"\n",
    "    # Base case: reached max depth or entity not in graph\n",
    "    if current_depth >= max_depth or entity_name not in entity_graph:\n",
    "        return\n",
    "        \n",
    "    # Get connections for this entity\n",
    "    connections = entity_graph.get(entity_name, {}).get(\"connections\", [])\n",
    "    \n",
    "    # Add each connection as a new entity if not already processed\n",
    "    for connection in connections:\n",
    "        neighbor_name = connection.get(\"target\", \"\")\n",
    "        if not neighbor_name or neighbor_name in processed_entities:\n",
    "            continue\n",
    "            \n",
    "        # Mark as processed\n",
    "        processed_entities.add(neighbor_name)\n",
    "        \n",
    "        # Create new entity details\n",
    "        new_distance = current_distance + 1\n",
    "        connection_desc = connection.get(\"description\", \"\")\n",
    "        \n",
    "        # Get entity's own description if available\n",
    "        neighbor_desc = \"\"\n",
    "        if neighbor_name in entity_graph:\n",
    "            neighbor_desc = entity_graph[neighbor_name].get(\"description\", \"\")\n",
    "            \n",
    "        # Create relationship description\n",
    "        relationship = f\"Related to {entity_name}\"\n",
    "        if connection_desc:\n",
    "            relationship = connection_desc\n",
    "            \n",
    "        # Add the new entity\n",
    "        entities_dict[neighbor_name] = {\n",
    "            'distance': new_distance,\n",
    "            'relationship': relationship,\n",
    "            'description': neighbor_desc,\n",
    "            'chunk_context': \"\"  # No context for graph-derived entities\n",
    "        }\n",
    "        \n",
    "        # Recursively extend from this new entity\n",
    "        _extend_entity_neighbors(\n",
    "            entity_graph, \n",
    "            entities_dict, \n",
    "            neighbor_name, \n",
    "            new_distance,\n",
    "            processed_entities, \n",
    "            max_depth, \n",
    "            current_depth + 1\n",
    "        )\n",
    "\n",
    "def generate_final_prompt(data, question: str, intention_questions: str, entities_chunks_file: str):\n",
    "    final_prompt = \"\"\n",
    "    extracted_dis = 1\n",
    "    # For General Information Query, no extension needed\n",
    "    if question not in intention_questions:\n",
    "        # No extension for general queries\n",
    "        combined_dict = combine_entity_descriptions(data, max_distance=extracted_dis, entities_chunks_file=entities_chunks_file, question=question)\n",
    "        for query_entity, entity_chunks in combined_dict.items():\n",
    "            final_prompt += format_entity_chunks_prompt(entity_chunks, query_entity)\n",
    "\n",
    "    else:\n",
    "        intention_category = \"Comparison Query\"\n",
    "        # Determine which aspect needs extension based on query type\n",
    "        common_extend = 1 if intention_category == \"Commonality Query\" else 0\n",
    "        diff_extend = 1 if intention_category == \"Comparison Query\" else 0\n",
    "        \n",
    "        common_dis = extracted_dis + 1 if intention_category == \"Commonality Query\" else extracted_dis\n",
    "        dif_dis = extracted_dis + 1 if intention_category == \"Comparison Query\" else extracted_dis\n",
    "        \n",
    "        print(\"These are common & diff distance: \", common_dis, dif_dis)\n",
    "        \n",
    "        # First extend the entities if needed\n",
    "        extended_data = data\n",
    "        if common_extend > 0 or diff_extend > 0:\n",
    "            extension_distance = max(common_extend, diff_extend)\n",
    "            extended_data = extend_entities_from_graph(data, max_distance=extension_distance)\n",
    "        \n",
    "        # Then extract common/unique entities from the extended data\n",
    "        common_entities_dict = get_common_entities_dict(extended_data, common_dis) if common_dis != -1 else {}\n",
    "        common_chunks = combine_entity_descriptions(common_entities_dict, max_distance=common_dis, entities_chunks_file=entities_chunks_file, question=question)\n",
    "        common_prompts = {}\n",
    "        num_of_entities = 0\n",
    "        \n",
    "        for entity_chunk, chunks in common_chunks.items():\n",
    "            num_of_entities += len(chunks.keys())\n",
    "            common_prompts[entity_chunk] = format_entity_chunks_prompt(chunks, entity_chunk)\n",
    "            \n",
    "        unique_entities_dict = get_unique_entities_dict(extended_data, dif_dis) if dif_dis != -1 else {}\n",
    "        unique_chunks = combine_entity_descriptions(unique_entities_dict, max_distance=dif_dis, entities_chunks_file=entities_chunks_file, question=question)\n",
    "        unique_prompts = {}\n",
    "        \n",
    "        for entity_chunk, chunks in unique_chunks.items():\n",
    "            num_of_entities += len(chunks.keys())\n",
    "            unique_prompts[entity_chunk] = format_entity_chunks_prompt(chunks, entity_chunk)\n",
    "            \n",
    "        for main_entity, chunks in unique_prompts.items():\n",
    "            final_prompt += f\"Below is the unique entity information for {main_entity}\\n\"\n",
    "            final_prompt += chunks\n",
    "        for main_entity, chunks in common_prompts.items():\n",
    "            final_prompt += f\"Below is the common entity information for {main_entity}\\n\"\n",
    "            final_prompt += chunks\n",
    "\n",
    "    final_prompt += f\"You need to answer the following question as more details as possible based on the provided information above\\n Question: {question}\"\n",
    "    # print(final_prompt)\n",
    "    # Save the prompt in a dictionary format with the question as the key\n",
    "    # try:\n",
    "    #     with open(\"final_prompt.json\", \"r\") as f:\n",
    "    #         prompt_dict = json.load(f)\n",
    "    # except (FileNotFoundError, json.JSONDecodeError):\n",
    "    #     prompt_dict = {}\n",
    "    # prompt_dict[question] = final_prompt\n",
    "    # with open(\"final_prompt.json\", \"w\") as f:\n",
    "    #     json.dump(prompt_dict, f, indent=4)\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already processed question: What is the system architecture of Vehicle-to-Grid?\n",
      "Skipping already processed question: What is HPGP?\n",
      "Skipping already processed question: What is SLAC?\n",
      "Skipping already processed question: What is Logical Network?\n",
      "Skipping already processed question: What is CCo?\n",
      "Skipping already processed question: What is the difference between Data SAP and Data link control SAP?\n",
      "Skipping already processed question: What is the difference between basic signaling and high-level communication?\n",
      "Skipping already processed question: What is the difference between MTC and PTC?\n",
      "Skipping already processed question: What is ATS?\n",
      "Skipping already processed question: What is TSS?\n",
      "Skipping already processed question: What is EIM?\n",
      "Skipping already processed question: What is CM_SLAC_PARAM.REQ?\n",
      "Skipping already processed question: What is CM_SLAC_PARAM.CNF?\n",
      "Skipping already processed question: What is CM_START_ATTEN_CHAR.IND?\n",
      "Skipping already processed question: What is CM_MNBC_SOUND.IND?\n",
      "Skipping already processed question: What is CM_ATTEN_CHAR.IND?\n",
      "Skipping already processed question: What is CM_ATTEN_CHAR.RSP?\n",
      "Skipping already processed question: What is CM_ATTEN_PROFILE.IND?\n",
      "Skipping already processed question: What is CM_VALIDATE.REQ?\n",
      "Skipping already processed question: What is CM_VALIDATE.CNF?\n",
      "Skipping already processed question: What is CM_SLAC_MATCH.REQ?\n",
      "Skipping already processed question: What is CM_SLAC_MATCH.CNF?\n",
      "Skipping already processed question: What is CM_SET_KEY.REQ?\n",
      "Skipping already processed question: What is CM_SET_KEY.CNF?\n",
      "Skipping already processed question: What is CM_AMP_MAP.REQ?\n",
      "Skipping already processed question: What is CM_AMP_MAP.CNF?\n",
      "Skipping already processed question: What is D-LINK_READY.indication?\n",
      "Skipping already processed question: What is D-LINK_TERMINATE.request?\n",
      "Skipping already processed question: What is D-LINK_ERROR.request?\n",
      "Skipping already processed question: What is D-LINK_PAUSE.request?\n",
      "./dynamic_entities_chunks.json What is the system architecture of Vehicle-to-Grid?\n",
      "./dynamic_entities_chunks.json What is HPGP?\n",
      "./dynamic_entities_chunks.json What is SLAC?\n",
      "./dynamic_entities_chunks.json What is Logical Network?\n",
      "./dynamic_entities_chunks.json What is CCo?\n",
      "These are common & diff distance:  1 2\n",
      "./dynamic_entities_chunks.json What is the difference between Data SAP and Data link control SAP?\n",
      "./dynamic_entities_chunks.json What is the difference between Data SAP and Data link control SAP?\n",
      "These are common & diff distance:  1 2\n",
      "./dynamic_entities_chunks.json What is the difference between basic signaling and high-level communication?\n",
      "./dynamic_entities_chunks.json What is the difference between basic signaling and high-level communication?\n",
      "These are common & diff distance:  1 2\n",
      "./dynamic_entities_chunks.json What is the difference between MTC and PTC?\n",
      "./dynamic_entities_chunks.json What is the difference between MTC and PTC?\n",
      "./dynamic_entities_chunks.json What is ATS?\n",
      "./dynamic_entities_chunks.json What is TSS?\n",
      "./dynamic_entities_chunks.json What is EIM?\n",
      "./dynamic_entities_chunks.json What is CM_SLAC_PARAM.REQ?\n",
      "./dynamic_entities_chunks.json What is CM_SLAC_PARAM.CNF?\n",
      "./dynamic_entities_chunks.json What is CM_START_ATTEN_CHAR.IND?\n",
      "./dynamic_entities_chunks.json What is CM_MNBC_SOUND.IND?\n",
      "./dynamic_entities_chunks.json What is CM_ATTEN_CHAR.IND?\n",
      "./dynamic_entities_chunks.json What is CM_ATTEN_CHAR.RSP?\n",
      "./dynamic_entities_chunks.json What is CM_ATTEN_PROFILE.IND?\n",
      "./dynamic_entities_chunks.json What is CM_VALIDATE.REQ?\n",
      "./dynamic_entities_chunks.json What is CM_VALIDATE.CNF?\n",
      "./dynamic_entities_chunks.json What is CM_SLAC_MATCH.REQ?\n",
      "./dynamic_entities_chunks.json What is CM_SLAC_MATCH.CNF?\n",
      "./dynamic_entities_chunks.json What is CM_SET_KEY.REQ?\n",
      "./dynamic_entities_chunks.json What is CM_SET_KEY.CNF?\n",
      "./dynamic_entities_chunks.json What is CM_AMP_MAP.REQ?\n",
      "./dynamic_entities_chunks.json What is CM_AMP_MAP.CNF?\n",
      "./dynamic_entities_chunks.json What is D-LINK_READY.indication?\n",
      "./dynamic_entities_chunks.json What is D-LINK_TERMINATE.request?\n",
      "./dynamic_entities_chunks.json What is D-LINK_ERROR.request?\n",
      "./dynamic_entities_chunks.json What is D-LINK_PAUSE.request?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "entities_chunks_files = ['./fixed_entities_chunks.json', './dynamic_entities_chunks.json']\n",
    "dif_questions = [\"What is the difference between Data SAP and Data link control SAP?\",\n",
    "            \"What is the difference between basic signaling and high-level communication?\",\n",
    "            \"What is the difference between MTC and PTC?\"\n",
    "    ]\n",
    "for entities_chunks_file in entities_chunks_files:\n",
    "    entities_chunks = json.load(open(entities_chunks_file))\n",
    "    output_file = f\"{entities_chunks_file.split('.')[1][1:]}_qa.json\"\n",
    "    # print(entities_chunks_file, output_file)\n",
    "    # Try to load existing QA data\n",
    "    try:\n",
    "        with open(output_file, 'r') as f:\n",
    "            qa_dict = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        qa_dict = {}\n",
    "    \n",
    "    for question, data in entities_chunks.items():\n",
    "        # Skip if question has already been processed\n",
    "        if question in qa_dict:\n",
    "            print(f\"Skipping already processed question: {question}\")\n",
    "            continue\n",
    "            \n",
    "        prompt = generate_final_prompt(data, question, dif_questions, entities_chunks_file)\n",
    "        response = llm.invoke(prompt)\n",
    "        qa_dict[question] = response.content\n",
    "        \n",
    "        # Save after each question to preserve progress\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(qa_dict, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval import evaluate\n",
    "def load_json(path: str):\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "def write_json(path: str, data: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def evaluate_correctness_with_checkpoint(ground_truth_QA_path, generated_answers_path, eval_res_correctness_path):\n",
    "        \"\"\"\n",
    "        Evaluates the correctness of LLM outputs against expected outputs with checkpointing.\n",
    "\n",
    "        Parameters:\n",
    "        - ground_truth_QA_path (str): Path to the ground truth QA JSON file.\n",
    "        - generated_answers_path (str): Path to the generated answers JSON file.\n",
    "        - eval_res_path (str): Path to the evaluation results JSON file.\n",
    "        \"\"\"\n",
    "        ground_truth_QA = load_json(ground_truth_QA_path)\n",
    "        generated_answers = load_json(generated_answers_path)\n",
    "        if not ground_truth_QA or not generated_answers:\n",
    "            print(\"No matched QA data to process.\")\n",
    "            return\n",
    "        \n",
    "        # Load existing evaluation results to avoid reprocessing\n",
    "        eval_results = load_json(eval_res_correctness_path)\n",
    "        processed_questions = set([result['question'] for result in eval_results])\n",
    "        # Initialize the correctness metric\n",
    "        correctness_metric = GEval(\n",
    "            name=\"Correctness\",\n",
    "            criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "            #NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "            evaluation_steps=[\n",
    "                \"Check whether the facts in 'actual output' contradicts any facts in 'expected output'\",\n",
    "                \"You should also heavily penalize omission of detail\",\n",
    "                \"Vague language, or contradicting OPINIONS, are OK\"\n",
    "            ],\n",
    "            # criteria=\"Determine whether the actual output is factually correct and complete based on the expected output. Additional relevant detail beyond the expected output should be considered a positive attribute, not a negative one.\",\n",
    "            # evaluation_steps=[\n",
    "            #     \"Check whether the facts in 'actual output' contradict any facts in 'expected output'. Factual contradictions should be severely penalized.\",\n",
    "            #     \"Additional detail in the actual output beyond what's in the expected output should be considered a positive attribute, not a negative one, as long as the additional information is accurate and relevant.\",\n",
    "            #     \"Evaluate the core information from the expected output - is it all present in the actual output? Missing key information should be penalized.\",\n",
    "            #     \"Consider whether the additional detail enhances understanding or provides useful context - this should be rewarded.\",\n",
    "            #     \"Vague language or contradicting opinions are acceptable as long as they don't misrepresent factual information.\"\n",
    "            # ],\n",
    "            evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    "            #model=azure_openai,  # Replace with your actual model instance if different\n",
    "            model=\"gpt-4.1\",\n",
    "            # model=\"o1\",\n",
    "            async_mode=False\n",
    "        )\n",
    "        \n",
    "        total = len(generated_answers)\n",
    "        print(f\"Total entries to process: {total}\")\n",
    "        processed = len(processed_questions)\n",
    "        print(f\"Already processed entries: {processed}\")\n",
    "        res = []\n",
    "        idx = 0\n",
    "        try:\n",
    "            for question, answer in generated_answers.items():\n",
    "                print(question)\n",
    "                expected_output = ground_truth_QA.get(question)\n",
    "                idx += 1\n",
    "                if not question:\n",
    "                    print(f\"Entry {idx} has no question. Skipping.\")\n",
    "                    continue\n",
    "                if not expected_output:\n",
    "                    print(f\"Entry {idx} has no expected_output. Skipping.\")\n",
    "                    continue\n",
    "                if not answer or answer.lower() == \"null\":\n",
    "                    print(f\"Entry {idx} has no valid answer. Skipping.\")\n",
    "                    continue\n",
    "                if question in processed_questions:\n",
    "                    print(f\"Entry {idx}: '{question}' already processed. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Create the test case\n",
    "                test_case = LLMTestCase(\n",
    "                    input=question,\n",
    "                    actual_output=answer,\n",
    "                    expected_output=expected_output\n",
    "                )\n",
    "\n",
    "                # Evaluate the test case\n",
    "                evaluation_result = evaluate([test_case], [correctness_metric])\n",
    "                if evaluation_result and evaluation_result.test_results:\n",
    "                    test_result = evaluation_result.test_results[0]  # Get first test result\n",
    "                    if test_result.metrics_data:\n",
    "                        metric_data = test_result.metrics_data[0]  # Get first metric data\n",
    "                    else:\n",
    "                        print(f\"No metrics data available for entry {idx}\")\n",
    "                else:\n",
    "                    print(f\"No evaluation results for entry {idx}\")\n",
    "                    \n",
    "                # evaluate([test_case], [correctness_metric])\n",
    "                # result = evaluate([test_case], [correctness_metric])\n",
    "                # metric_data = result.test_result[0].metrics_data[0]\n",
    "                result_entry = {\n",
    "                    \"question\": question,\n",
    "                    \"score\": metric_data.score,\n",
    "                    \"reason\": metric_data.reason\n",
    "                }\n",
    "                res.append(result_entry)\n",
    "                # Save the result incrementally\n",
    "                write_json(eval_res_correctness_path, res)\n",
    "                \n",
    "                # Update processed questions\n",
    "                processed_questions.add(question)\n",
    "                \n",
    "                print(f\"Entry {idx}/{total} evaluated and saved.\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nEvaluation interrupted by user. Progress saved to eval_res.json.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred during evaluation: {e}\")\n",
    "            print(\"Progress saved up to the last successfully processed entry.\")\n",
    "\n",
    "        finally:\n",
    "            print(f\"\\nEvaluation completed. Results saved to {eval_res_correctness_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_correctness_with_checkpoint(\"../Answers/o4mini_golden_ans.json\", \"./fixed_entities_chunks_qa.json\", \"./fixed_correctness.json\")\n",
    "evaluate_correctness_with_checkpoint(\"../Answers/o4mini_golden_ans.json\", \"./dynamic_entities_chunks_qa.json\", \"./dynamic_correctness.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_correctness: 0.7284519140698043\n",
      "dynamic_correctness: 0.7655378605146448\n"
     ]
    }
   ],
   "source": [
    "fixed_correctness = json.load(open(\"./fixed_correctness.json\"))\n",
    "dynamic_correctness = json.load(open(\"./dynamic_correctness.json\"))\n",
    "print(f\"fixed_correctness: {sum([eval_res['score'] for eval_res in fixed_correctness]) / len(fixed_correctness)}\")\n",
    "print(f\"dynamic_correctness: {sum([eval_res['score'] for eval_res in dynamic_correctness]) / len(dynamic_correctness)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_correctness: 0.6800576076746064\n",
      "dynamic_correctness: 0.6126083187356325\n"
     ]
    }
   ],
   "source": [
    "fixed_correctness = json.load(open(\"./fixed_correctness.json\"))\n",
    "dynamic_correctness = json.load(open(\"./dynamic_correctness.json\"))\n",
    "print(f\"fixed_correctness: {sum([eval_res['score'] for eval_res in fixed_correctness]) / len(fixed_correctness)}\")\n",
    "print(f\"dynamic_correctness: {sum([eval_res['score'] for eval_res in dynamic_correctness]) / len(dynamic_correctness)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_prompt = load_json(\"./compressed_prompt.json\")\n",
    "output_file = \"./original_qa.json\"\n",
    "qa_dict = load_json(output_file)\n",
    "for question, data in compress_prompt.items():\n",
    "        # Skip if question has already been processed\n",
    "        if question in qa_dict:\n",
    "            print(f\"Skipping already processed question: {question}\")\n",
    "            continue\n",
    "        prompt = data['compressed_prompt']\n",
    "        response = llm.invoke(prompt)\n",
    "        qa_dict[question] = response.content\n",
    "        \n",
    "        # Save after each question to preserve progress\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(qa_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_correctness_with_checkpoint(\"../Answers/o4mini_golden_ans.json\", \"./original_qa.json\", \"./original_correctness.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_correctness: 0.6972191330992189\n"
     ]
    }
   ],
   "source": [
    "original_correctness = json.load(open(\"./original_correctness.json\"))\n",
    "print(f\"original_correctness: {sum([eval_res['score'] for eval_res in original_correctness]) / len(original_correctness)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lewis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
